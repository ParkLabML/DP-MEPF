# dp-mepf code


## code structure

### Most important files:

- `dp_mepf.py` This is the main function to run. read through main() to get an idea of the structure
- `dp_mepf_args.py` all the flags that may be set for dp_mepf.py (includes unused features)


### Remaining files:

- `data_loading.py` prepares the dataloader
- `downstream_models.py` models for labeled cifar10 classification accuracy eval
- `dp_analysis.py` functions to get Gaussian mechanism noise variables based on desired eps,delta guarantee
- `dp_functions.py` everything related to sensitivity bounding and DP release
- `encoders_class.py` wrapper class for feature encoder networks
- `eval_accuracy.py` downstream accuracy score computation
- `eval_fid.py` FID score computation
- `eval_prdc.py` Precision/Recall and Density/Coverage score computation
- `feature_matching.py` functions used for feature matching updates (regular or adam)
- `generators.py` generator network definitions
- `mnist_gen_model.py`
- `mnist_synth_data_benchmark.py` (Fashion)MNIST classification accuracy eval 
- `model_builder.py` gives access to all NNs used in the code
- `resnet.py` resnet18 used as (Fashion)MNIST encoder
- `resnet20.py` resnet20 used for DP pretraining experiments (Table 19)
- `util.py` various utility functions
- `util_logging.py` utility functions specific to logging experiments


## How to run:

### 1) notable flags:
- `--seed`: value of random seed to use. we chose 1, 2, and 3
- `--matched_moments`: either `mean` or `m1_and_m2` to indicate whether we match phi_1 or both phi_1 and phi_2.
- `--dp_tgt_eps`: the desired DP constant epsilon. the necessary noise is computed.
- `--no_io_files`: by default, io is routed to files in the log directory. this flag disables this
- `--restart_iter`: by default, program exits with exit code 3 after this many iterations to trigger a restart on the cluster we used for training. Set to None or negative number to turn off.

### 2) Run via command line

all experiments were performed with random seeds `1`,`2` and `3` (and `4`, `5` for CelebA and Cifar10), for matching only phi_1 or phi_1 and phi_2, and at various levels of privacy.
Below we only list one nonprivate and one private run for each dataset. the other runs can be generated by changing the `seed`, `matched_moments` and `tgt_eps` arguments accordingly.


#### CelebA 32x32
`python3.9 dp_mepf.py --n_iter 200_000 --ckpt_iter 10_000 --restart_iter 210_000 --syn_eval_iter 5_000 --dataset celeba --gen_output tanh --keep_best_syn_data --exp_name may28_tanh_celeba32_res/run_162 --image_size 32 --dp_val_noise_scaling 10. --batch_size 128 --extra_input_scaling imagenet_norm --matched_moments mean --dp_tgt_eps 1. --lr 3e-4 --m_avg_lr 1e-4 --seed 1`

#### CelebA 64x64
`python3.9 dp_mepf.py --n_iter 200_000 --ckpt_iter 10_000 --restart_iter 210_000 --syn_eval_iter 5_000 --dataset celeba --gen_output tanh --keep_best_syn_data --exp_name may29_tanh_celeba64_res_mean/run_0 --image_size 64 --dp_val_noise_scaling 10. --batch_size 128 --extra_input_scaling imagenet_norm  --matched_moments mean --dp_tgt_eps 1. --lr 3e-4 --m_avg_lr 3e-4 --seed 1`

#### Cifar10 - labeled
`python3.9 dp_mepf.py --n_iter 200_000 --ckpt_iter 20_000 --restart_iter 210_000 --syn_eval_iter 5_000 --dataset cifar10 --gen_output tanh --keep_best_syn_data --labeled --exp_name jun2_tanh_cifar10_labeled_res_mean/run_0 --dp_val_noise_scaling 10. --batch_size 128 --extra_input_scaling imagenet_norm --matched_moments mean --dp_tgt_eps 1. --lr 1e-3 --m_avg_lr 1e-4 --seed 1`

#### Cifar10 - unlabeled
`python3.9 dp_mepf.py --n_iter 200_000 --ckpt_iter 20_000 --restart_iter 210_000 --syn_eval_iter 5_000 --dataset cifar10 --gen_output tanh --keep_best_syn_data --exp_name may26_tanh_cifar10_res_unlabeled/run_0 --matched_moments mean --dp_val_noise_scaling 10. --batch_size 128 --extra_input_scaling imagenet_norm --lr 1e-3 --m_avg_lr 1e-3 --dp_tgt_eps 1. --seed 1`

#### MNIST / FashionMNIST
This version of the code was corrected and refactored after we found an error in our FID evaluation. As a result, (Fashion)MNIST experiments, which were not affected by the error, have not been tested with this new version. To reproduce our results on those datasets, use our old implementation in `old_code`. 
